{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Calculate Tensor Shape!**\n",
    "Formula:\n",
    "1. Convolution:\n",
    "output dim = (input dim - filter size + 2 * padding)/stride + 1\n",
    "<br>depth = # convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'macOS-10.16-x86_64-i386-64bit'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "platform.platform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of image_t, [C, H, W]: torch.Size([2, 256, 232])\n",
      "Shape of image_concat, [N, C, H, W]: torch.Size([2, 2, 256, 232]) where N = the first 2\n",
      "Shape of image_concat, [N, C, H, W]: torch.Size([1, 2, 256, 232]) where N = the first 1\n",
      "Shape of image_concat, [C, H, W]: torch.Size([2, 256, 232])\n"
     ]
    }
   ],
   "source": [
    "H = 256\n",
    "W = 232\n",
    "C = 2\n",
    "N = 1\n",
    "image = np.zeros(shape=(H, W, C))\n",
    "image_t = ToTensor()(image)\n",
    "print(f\"Shape of image_t, [C, H, W]: {image_t.shape}\")\n",
    "image_concat = torch.stack([image_t, image_t], dim=0)\n",
    "print(f\"Shape of image_concat, [N, C, H, W]: {image_concat.shape} where N = the first 2\")\n",
    "image_dummy = image_t[None,:] # adding dummy dimension!\n",
    "print(f\"Shape of image_concat, [N, C, H, W]: {image_dummy.shape} where N = the first 1\")\n",
    "image_0 = torch.zeros(C, H, W)\n",
    "print(f\"Shape of image_concat, [C, H, W]: {image_0.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(tensor, count, filter, padding, stride):\n",
    "    C = tensor.shape[0]\n",
    "    H = tensor.shape[1]\n",
    "    W = tensor.shape[2]\n",
    "    new_C = int(count)\n",
    "    new_H = int((H - filter + 2 * padding)/stride + 1)\n",
    "    new_W = int((W - filter + 2 * padding)/stride + 1)\n",
    "    new_image = torch.zeros((new_C, new_H, new_W))\n",
    "    return new_image  \n",
    "def transpose_convolution(tensor, count, filter, padding, stride):\n",
    "    C = tensor.shape[0]\n",
    "    H = tensor.shape[1]\n",
    "    W = tensor.shape[2]\n",
    "    new_C = int(count)\n",
    "    new_H = int(stride * (H - 1) + filter - 2 * padding)\n",
    "    new_W = int(stride * (W - 1) + filter - 2 * padding)\n",
    "    # print(f\"{new_W} = int({stride} * ({W} - 1) + {filter} - 2 * {padding})\")\n",
    "    new_image = torch.zeros((new_C, new_H, new_W))\n",
    "    return new_image\n",
    "def max_pooling(tensor, F, P, S):\n",
    "    C = tensor.shape[0]\n",
    "    return convolution(tensor=tensor, count=C, filter=F, padding=P, stride=S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 232])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels = 2\n",
    "height = 256\n",
    "width = 232\n",
    "input = torch.zeros(channels, height, width)\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of A: torch.Size([10, 1, 2, 3])\n",
      "shape of B: torch.Size([10, 1, 4, 5])\n",
      "shape of C: torch.Size([10, 1, 2, 3])\n",
      "shape of D: torch.Size([10, 2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "A = torch.zeros(10, 1,2,3)\n",
    "print(f\"shape of A: {A.shape}\")\n",
    "B = torch.zeros(10, 1,4,5)\n",
    "print(f\"shape of B: {B.shape}\")\n",
    "C = T.CenterCrop(size=(A.shape[2], A.shape[3]))(B)\n",
    "print(f\"shape of C: {C.shape}\")\n",
    "D = torch.cat([A, C],dim=1)\n",
    "print(f\"shape of D: {D.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: [C, H, W]: torch.Size([64, 568, 568])\n",
      "Shape: [C, H, W]: torch.Size([64, 284, 284])\n"
     ]
    }
   ],
   "source": [
    "d1_1 = convolution(input, count=64, filter=3, padding=0, stride=1)\n",
    "d1_2 = convolution(d1_1, count=64, filter=3, padding=0, stride=1)\n",
    "print(f\"Shape: [C, H, W]: {d1_2.shape}\")\n",
    "dt_1 = max_pooling(d1_2, 2, 0, 2)\n",
    "print(f\"Shape: [C, H, W]: {dt_1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going down\n",
      "Shape of contract 1: torch.Size([64, 252, 228]), will concat\n",
      "Shape of contract 2: torch.Size([128, 122, 110]), will concat\n",
      "Shape of BOTM: torch.Size([256, 116, 104])\n",
      "Shape of expand 1: torch.Size([128, 240, 216]), for concat\n",
      "Shape of expand 2: torch.Size([128, 240, 216]), for concat\n",
      "Shape of out: torch.Size([2, 484, 436])\n"
     ]
    }
   ],
   "source": [
    "# neural network\n",
    "print(\"going down\")\n",
    "d1_1 = convolution(input, count=64, filter=3, padding=0, stride=1) # <- contract 1\n",
    "d1_2 = convolution(d1_1, count=64, filter=3, padding=0, stride=1)\n",
    "print(f\"Shape of contract 1: {d1_2.shape}, will concat\")\n",
    "dp1 = max_pooling(d1_2, 2, 0, 2)\n",
    "d2_1 = convolution(dp1, count=128, filter=3, padding=0, stride=1) # <- contract 2\n",
    "d2_2 = convolution(d2_1, count=128, filter=3, padding=0, stride=1)\n",
    "print(f\"Shape of contract 2: {d2_2.shape}, will concat\")\n",
    "dp2 = max_pooling(d2_2, 3, 0, 1)\n",
    "db_1 = convolution(dp2, count=256, filter=3, padding=0, stride=1) # <- bottom\n",
    "db_2 = convolution(db_1, count=256, filter=3, padding=0, stride=1)\n",
    "print(f\"Shape of BOTM: {db_2.shape}\")\n",
    "up1 = transpose_convolution(db_2, count=128, filter=10, padding=0, stride=2)\n",
    "print(f\"Shape of expand 1: {up1.shape}, for concat\")\n",
    "u1_1 = convolution(up1, count=128, filter=3, padding=0, stride=1) # <- expand 1\n",
    "u1_2 = convolution(u1_1, count=128, filter=3, padding=0, stride=1)\n",
    "up2 = transpose_convolution(u1_2, count=64, filter=18, padding=0, stride=2)\n",
    "print(f\"Shape of expand 2: {up1.shape}, for concat\")\n",
    "u2_1 = convolution(up2, count=64, filter=3, padding=0, stride=1) # <- expand 2\n",
    "u2_2 = convolution(u2_1, count=64, filter=3, padding=0, stride=1)\n",
    "out = convolution(u2_2, count=2, filter=1, padding=0, stride=1)\n",
    "print(f\"Shape of out: {out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = int((568 - 2 + 2 * 0)/2 + 1)\n",
    "q\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generalPurpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ba8ef3e7b2db9f7a54513b628fe96659401697d721e3769996c9efe2f0233a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
